{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"mioti.png\" style=\"height: 100px\">\n",
    "<center style=\"color:#888\">Módulo Data Science in IoT<br/>Asignatura Data preprocessing</center>\n",
    "\n",
    "# Challenge S7: Clasificación de sentimientos en tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de este challenge es enfrentarse a un problema de clasificación de texto real: tweets descargados sobre las elecciones de EEUU en 2016, centrándonos en el preprocesamiento, que en este caso es crucial en un problema en el que el protagonista es el texto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicialización del entorno:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.classify import SklearnClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import random\n",
    "\n",
    "random.seed(1234)\n",
    "pd.set_option('display.max_colwidth', 175) # incrementamos anchura de output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8414 entries, 0 to 8413\n",
      "Data columns (total 2 columns):\n",
      "sentiment    8414 non-null object\n",
      "text         8414 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 131.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('./data/gop_tweets_train_psn.csv')\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2153 entries, 0 to 2152\n",
      "Data columns (total 2 columns):\n",
      "sentiment    2153 non-null object\n",
      "text         2153 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 33.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv('./data/gop_tweets_test_psn.csv')\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Damos un vistazo a los textos que aparecen en el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>RT @NancyLeeGrahn: How did everyone feel about the Climate Change question last night? Exactly. #GOPDebate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "      <td>RT @ScottWalker: Didn't catch the full #GOPdebate last night. Here are some of Scott's best lines in 90 seconds. #Walker16 http://t.co/ZSfF…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>RT @TJMShow: No mention of Tamir Rice and the #GOPDebate was held in Cleveland? Wow.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positive</td>\n",
       "      <td>RT @RobGeorge: That Carly Fiorina is trending -- hours after HER debate -- above any of the men in just-completed #GOPdebate says she's on …</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Positive</td>\n",
       "      <td>RT @DanScavino: #GOPDebate w/ @realDonaldTrump delivered the highest ratings in the history of presidential debates. #Trump2016 http://t.co…</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment  \\\n",
       "0   Neutral   \n",
       "1  Positive   \n",
       "2   Neutral   \n",
       "3  Positive   \n",
       "4  Positive   \n",
       "\n",
       "                                                                                                                                           text  \n",
       "0                                    RT @NancyLeeGrahn: How did everyone feel about the Climate Change question last night? Exactly. #GOPDebate  \n",
       "1  RT @ScottWalker: Didn't catch the full #GOPdebate last night. Here are some of Scott's best lines in 90 seconds. #Walker16 http://t.co/ZSfF…  \n",
       "2                                                          RT @TJMShow: No mention of Tamir Rice and the #GOPDebate was held in Cleveland? Wow.  \n",
       "3  RT @RobGeorge: That Carly Fiorina is trending -- hours after HER debate -- above any of the men in just-completed #GOPdebate says she's on …  \n",
       "4  RT @DanScavino: #GOPDebate w/ @realDonaldTrump delivered the highest ratings in the history of presidential debates. #Trump2016 http://t.co…  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Positive</td>\n",
       "      <td>RT @GregAbbott_TX: @TedCruz: \"On my first day I will rescind every illegal executive action taken by Barack Obama.\" #GOPDebate @FoxNews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>Going on #MSNBC Live with @ThomasARoberts around 2 PM ET.  #GOPDebate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positive</td>\n",
       "      <td>RT @WayneDupreeShow: Just woke up to tweet this out #GOPDebate \\r\\n\\r\\nBest line of the night via @GovMikeHuckabee http://t.co/6OV5hxHIcV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Negative</td>\n",
       "      <td>reason comment is funny 'in case you're ignorant' is the #gop #tcot are the reason the government isn't working for the people #gopdebate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Positive</td>\n",
       "      <td>RT @ChuckNellis: Cruz has class &amp;amp; truth, that gets my vote! #GOPDebate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment  \\\n",
       "0  Positive   \n",
       "1   Neutral   \n",
       "2  Positive   \n",
       "3  Negative   \n",
       "4  Positive   \n",
       "\n",
       "                                                                                                                                        text  \n",
       "0    RT @GregAbbott_TX: @TedCruz: \"On my first day I will rescind every illegal executive action taken by Barack Obama.\" #GOPDebate @FoxNews  \n",
       "1                                                                      Going on #MSNBC Live with @ThomasARoberts around 2 PM ET.  #GOPDebate  \n",
       "2  RT @WayneDupreeShow: Just woke up to tweet this out #GOPDebate \\r\\n\\r\\nBest line of the night via @GovMikeHuckabee http://t.co/6OV5hxHIcV  \n",
       "3  reason comment is funny 'in case you're ignorant' is the #gop #tcot are the reason the government isn't working for the people #gopdebate  \n",
       "4                                                                 RT @ChuckNellis: Cruz has class &amp; truth, that gets my vote! #GOPDebate  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Qué número de tweets tenemos en cada dataset? ¿Cuántos de cada clase?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Negative    0.579035\n",
       "Neutral     0.256953\n",
       "Positive    0.164012\n",
       "Name: sentiment, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"sentiment\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Qué dificultades crees que presenta la diferencia entre la cantidad de clases?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Negative    0.583837\n",
       "Neutral     0.263353\n",
       "Positive    0.152810\n",
       "Name: sentiment, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[\"sentiment\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificador de tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a construir nuestro propio clasificador sobre los tweets que hemos cargado. Los pasos que seguiremos serán:\n",
    "\n",
    "* Preprocesar ambos conjuntos de tweets por separado.\n",
    "* Entrenar clasificador con tweets de entrenamiento.\n",
    "* Evaluar con tweets de test.\n",
    "\n",
    "Primero, haremos una prueba para observar el rendimiento de nuestro clasificador sin ningún tipo de preprocesamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seguimos creando el clasificador y entrenando con el conjunto de entrenamiento de los tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('clf',\n",
       "                 LinearSVC(C=1.0, class_weight=None, dual=True,\n",
       "                           fit_intercept=True, intercept_scaling=1,\n",
       "                           loss='squared_hinge', max_iter=1200,\n",
       "                           multi_class='ovr', penalty='l2', random_state=None,\n",
       "                           tol=0.0001, verbose=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creamos nuestro pipeline con vectorizador (bag of words) y clasificador\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('clf', LinearSVC(max_iter=1200))])\n",
    "\n",
    "# entrenamos el clasificador\n",
    "text_clf.fit(df_train['text'], df_train['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos las predicciones con el conjunto de test y obtenemos la métrica de evaluación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5973060845332094"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = text_clf.predict(df_test['text'])\n",
    "np.mean(predicted == df_test['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que hemos obtenido un resultado un poco peor... Ahora es cuando entra en juego el preprocesamiento del texto.\n",
    "\n",
    "Ahora vamos a preprocesar el texto y construir un clasificador. Para ello, se ha creado esta función que nos automatiza el preprocesamiento. Deberás añadir el código que creas necesario y ejecutar la función para obtener el texto preprocesado. \n",
    "\n",
    "**Puedes definir todas las funciones de preprocesado que creas necesario, pero ten en cuenta varios detalles:**\n",
    "* La funcion `preprocesar_texto` es llamada desde un `apply`. Esto significa que la función recibe un tweet y devuelve un tweet preprocesado con cada llamada. \n",
    "* Si el preprocesado es muy agresivo, un tweet puede quedarse fácilmente vacío, en esos casos el clasificador no podrá trabajar con él y escupirá la clase mayoritaria para ese tweet.\n",
    "* Algunas técnicas no tienen sentido si se aplican después de otras dentro del pipeline. Por ejemplo, no tiene sentido aplicar POS después de realizar Stemming.\n",
    "* Count Vectorizer necesita DOCUMENTOS y al trabajar con texto muchas veces es más sencillo hacer uso de TOKENS. Esto significa que tendremos que pasar cada tweet preprocesado en una cadena de texto. La función `\" \".join(palabras)` que vimos en el worksheet es tu aliada.\n",
    "* Si tu preprocesamiento va a ser intensivo, quizás es buena idea crear varias funciones que sean llamadas desde `preprocesar_texto`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"rt @scottwalker: didn't catch the full #gopdebate last night. here are some of scott's best lines in 90 seconds. #walker16 http://t.co/zsff…\""
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A minúsculas\n",
    "def to_lower(text):\n",
    "    return text.lower()\n",
    "\n",
    "text_lower = to_lower(df_train['text'][1])\n",
    "text_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rt', ':', \"didn't\", 'catch', 'the', 'full', '#gopdebate', 'last', 'night', '.', 'here', 'are', 'some', 'of', \"scott's\", 'best', 'lines', 'in', '90', 'seconds', '.', '#walker16', 'http://t.co/zsff…']\n"
     ]
    }
   ],
   "source": [
    "## Tokenizamos\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "def get_tokens(text):\n",
    "    return TweetTokenizer(strip_handles=True).tokenize(text)\n",
    "\n",
    "text_tokens = get_tokens(text_lower)\n",
    "print(text_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rt', 'catch', 'full', '#gopdebate', 'last', 'night', \"scott's\", 'best', 'lines', '90', 'seconds', '#walker16', 'http://t.co/zsff…']\n"
     ]
    }
   ],
   "source": [
    "## Limpiamos stopwords\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "stopwords.extend([\n",
    "    '``','/','=','(',')','\\'','...','-',\n",
    "    ',', '.', ';', ':', '?', '¿', '!', '¡',\n",
    "    '%','🇸','🇺','@','http',\n",
    "    '…','\\\"','&','’','“','”','#'\n",
    "])\n",
    "\n",
    "def clean_stopwords(tokens, stopwords):\n",
    "    clean_tokens = []\n",
    "    for token in tokens:\n",
    "        if token in stopwords:\n",
    "            continue\n",
    "        clean_tokens.append(token)\n",
    "    return clean_tokens\n",
    "\n",
    "clean_tokens = clean_stopwords(text_tokens, stopwords)\n",
    "print(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['catch', 'full', 'last', 'night', \"scott's\", 'best', 'lines', '90', 'seconds']\n"
     ]
    }
   ],
   "source": [
    "# limpiamos más basura\n",
    "\n",
    "def clean_twitter_conventions(tokens):\n",
    "    clean_tokens = []\n",
    "    for token in tokens:\n",
    "        if token.find('@') >= 0 or token.find('#') >= 0:\n",
    "            continue\n",
    "            \n",
    "        if token.find('http') >= 0:\n",
    "            continue\n",
    "        \n",
    "        if token == 'rt':\n",
    "            continue\n",
    "        \n",
    "        clean_tokens.append(token)\n",
    "    return clean_tokens\n",
    "\n",
    "clean_tokens = clean_twitter_conventions(clean_tokens)\n",
    "print(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['catch', 'full', 'last', 'night', 'scott', 'best', 'line', '90', 'second']\n"
     ]
    }
   ],
   "source": [
    "# stemming\n",
    "from nltk.stem import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "def get_stemmed_text(clean_tokens, stemmer):\n",
    "    tokens_stem = []\n",
    "    for token in clean_tokens:\n",
    "        tokens_stem.append(stemmer.stem(token))\n",
    "    \n",
    "    return tokens_stem\n",
    "\n",
    "clean_tokens = get_stemmed_text(clean_tokens, stemmer)\n",
    "print(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['catch', 'full', 'last', 'night', 'scott', 'line', 'second']\n"
     ]
    }
   ],
   "source": [
    "# filtrar POS\n",
    "from nltk import pos_tag\n",
    "selected_pos = ['JJ', 'NN', 'NNS']\n",
    "\n",
    "def filter_pos(clean_tokens, selected_tokens, pos_tag):\n",
    "    tokens_filtered = []\n",
    "    pos = pos_tag(clean_tokens)\n",
    "    for p in pos:\n",
    "        if p[1] in selected_pos:\n",
    "            tokens_filtered.append(p[0])\n",
    "            \n",
    "    return tokens_filtered\n",
    "\n",
    "clean_tokens = filter_pos(clean_tokens, selected_tokens, pos_tag)\n",
    "print(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocesar_texto(texto):\n",
    "    \"\"\" Función para preprocesamiento de texto.\n",
    "    Args:\n",
    "        texto: cadena de texto a preprocesar.\n",
    "    Returns:\n",
    "        mismo texto preprocesado.\n",
    "    \"\"\"\n",
    "    texto_filtrado = \"\"\n",
    "    texto_filtrado = to_lower(texto)\n",
    "    texto_filtrado = get_tokens(texto_filtrado)\n",
    "    texto_filtrado = clean_stopwords(texto_filtrado, stopwords)\n",
    "    texto_filtrado = clean_twitter_conventions(texto_filtrado)\n",
    "    \n",
    "    # técnicas que con una implementación sencilla no logran mejorar resultados\n",
    "    # texto_filtrado = filter_pos(texto_filtrado, selected_tokens, pos_tag)\n",
    "    # texto_filtrado = get_stemmed_text(texto_filtrado, stemmer)\n",
    "    \n",
    "    \n",
    "    texto_filtrado = ' '.join(texto_filtrado)\n",
    "    return texto_filtrado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos el preprocesamiento a los dos conjuntos de tweets y lo guardamos en la columna `prep`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['prep'] = df_train['text'].apply(preprocesar_texto)\n",
    "df_test['prep'] = df_test['text'].apply(preprocesar_texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de reentrenar nuestro clasificador, siempre es recomendable dar un vistazo al resultado del texto. Podemos observar frecuencia de palabras o simplemente generar un WordCloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           everyone feel climate change question last night exactly\n",
       "1                catch full last night scott's best lines 90 seconds\n",
       "2                              mention tamir rice held cleveland wow\n",
       "3        carly fiorina trending hours debate men just-completed says\n",
       "4           w delivered highest ratings history presidential debates\n",
       "5                          liked happy heard going moderator anymore\n",
       "6    deer headlights ben carson may brain surgeon performed lobotomy\n",
       "7                                         last night's debate proved\n",
       "8                                               fairness owns phrase\n",
       "9                                    reading family's comments great\n",
       "Name: prep, dtype: object"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['prep'][0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora sí, vamos a reentrenar el clasificador y evaluar de nuevo. Puedes hacer uso del mismo pipeline anterior o simplemente crear uno nuevo con más etapas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nuevo pipeline si es que es necesario. Por defecto usamos el anterior.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "new_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                    ('tfidf', TfidfTransformer(use_idf = True, smooth_idf=True)),\n",
    "                    ('clf', LinearSVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('clf',\n",
       "                 LinearSVC(C=1.0, class_weight=None, dual=True,\n",
       "                           fit_intercept=True, intercept_scaling=1,\n",
       "                           loss='squared_hinge', max_iter=1000,\n",
       "                           multi_class='ovr', penalty='l2', random_state=None,\n",
       "                           tol=0.0001, verbose=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_clf.fit(df_train['text'], df_train['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6228518346493265"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicción haciendo uso del pipeline correspondiente. ¡Recuerda cambiarlo si has creado uno nuevo!\n",
    "predicted = new_clf.predict(df_test['prep'])\n",
    "np.mean(predicted == df_test['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ¿Qué opinas de los resultados obtenidos?\n",
    "* ¿Por qué crees que ha sucedido esto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Podrías explicarme con tus palabras en qué consiste Tf-Idf? ¿Cual es la idea intuitiva de aplicar esta transformación a la matriz?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tf-Idf es una técnica que se aplica a la matriz de documentos-términos. Significa \"term frequency - inverse document frequency\" y es una técnica que especifica cómo de importante es un término dentro de una colección de documentos. A su vez, está formada por dos técnicas diferentes que son las siguientes:\n",
    "\n",
    "* Term frequency: que recompensa aquellas palabras que aparecen a menudo en un documento.\n",
    "* Inverse document frequency: que penaliza aquellas palabras que aparecen a menudo en una colección de documentos.\n",
    "\n",
    "Intuitivamente, buscará los términos más importantes para identificar un documento dentro de una colección de documentos. Hará que aumente el valor ponderado del término dentro de un documento, pero disminuirá su valor si este término es común en muchos documentos. A mayor importancia, más alto es el valor en el resultado final."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
