{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"mioti.png\" style=\"height: 100px\">\n",
    "<center style=\"color:#888\">M√≥dulo Data Science in IoT<br/>Asignatura Data preprocessing</center>\n",
    "\n",
    "# Challenge S7: Clasificaci√≥n de sentimientos en tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de este challenge es enfrentarse a un problema de clasificaci√≥n de texto real: tweets descargados sobre las elecciones de EEUU en 2016, centr√°ndonos en el preprocesamiento, que en este caso es crucial en un problema en el que el protagonista es el texto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicializaci√≥n del entorno:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.classify import SklearnClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import random\n",
    "\n",
    "random.seed(1234)\n",
    "pd.set_option('display.max_colwidth', 175) # incrementamos anchura de output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8414 entries, 0 to 8413\n",
      "Data columns (total 2 columns):\n",
      "sentiment    8414 non-null object\n",
      "text         8414 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 131.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('./data/gop_tweets_train_psn.csv')\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2153 entries, 0 to 2152\n",
      "Data columns (total 2 columns):\n",
      "sentiment    2153 non-null object\n",
      "text         2153 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 33.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv('./data/gop_tweets_test_psn.csv')\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Damos un vistazo a los textos que aparecen en el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>RT @NancyLeeGrahn: How did everyone feel about the Climate Change question last night? Exactly. #GOPDebate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "      <td>RT @ScottWalker: Didn't catch the full #GOPdebate last night. Here are some of Scott's best lines in 90 seconds. #Walker16 http://t.co/ZSfF‚Ä¶</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>RT @TJMShow: No mention of Tamir Rice and the #GOPDebate was held in Cleveland? Wow.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positive</td>\n",
       "      <td>RT @RobGeorge: That Carly Fiorina is trending -- hours after HER debate -- above any of the men in just-completed #GOPdebate says she's on ‚Ä¶</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Positive</td>\n",
       "      <td>RT @DanScavino: #GOPDebate w/ @realDonaldTrump delivered the highest ratings in the history of presidential debates. #Trump2016 http://t.co‚Ä¶</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment  \\\n",
       "0   Neutral   \n",
       "1  Positive   \n",
       "2   Neutral   \n",
       "3  Positive   \n",
       "4  Positive   \n",
       "\n",
       "                                                                                                                                           text  \n",
       "0                                    RT @NancyLeeGrahn: How did everyone feel about the Climate Change question last night? Exactly. #GOPDebate  \n",
       "1  RT @ScottWalker: Didn't catch the full #GOPdebate last night. Here are some of Scott's best lines in 90 seconds. #Walker16 http://t.co/ZSfF‚Ä¶  \n",
       "2                                                          RT @TJMShow: No mention of Tamir Rice and the #GOPDebate was held in Cleveland? Wow.  \n",
       "3  RT @RobGeorge: That Carly Fiorina is trending -- hours after HER debate -- above any of the men in just-completed #GOPdebate says she's on ‚Ä¶  \n",
       "4  RT @DanScavino: #GOPDebate w/ @realDonaldTrump delivered the highest ratings in the history of presidential debates. #Trump2016 http://t.co‚Ä¶  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Positive</td>\n",
       "      <td>RT @GregAbbott_TX: @TedCruz: \"On my first day I will rescind every illegal executive action taken by Barack Obama.\" #GOPDebate @FoxNews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>Going on #MSNBC Live with @ThomasARoberts around 2 PM ET.  #GOPDebate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positive</td>\n",
       "      <td>RT @WayneDupreeShow: Just woke up to tweet this out #GOPDebate \\r\\n\\r\\nBest line of the night via @GovMikeHuckabee http://t.co/6OV5hxHIcV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Negative</td>\n",
       "      <td>reason comment is funny 'in case you're ignorant' is the #gop #tcot are the reason the government isn't working for the people #gopdebate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Positive</td>\n",
       "      <td>RT @ChuckNellis: Cruz has class &amp;amp; truth, that gets my vote! #GOPDebate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment  \\\n",
       "0  Positive   \n",
       "1   Neutral   \n",
       "2  Positive   \n",
       "3  Negative   \n",
       "4  Positive   \n",
       "\n",
       "                                                                                                                                        text  \n",
       "0    RT @GregAbbott_TX: @TedCruz: \"On my first day I will rescind every illegal executive action taken by Barack Obama.\" #GOPDebate @FoxNews  \n",
       "1                                                                      Going on #MSNBC Live with @ThomasARoberts around 2 PM ET.  #GOPDebate  \n",
       "2  RT @WayneDupreeShow: Just woke up to tweet this out #GOPDebate \\r\\n\\r\\nBest line of the night via @GovMikeHuckabee http://t.co/6OV5hxHIcV  \n",
       "3  reason comment is funny 'in case you're ignorant' is the #gop #tcot are the reason the government isn't working for the people #gopdebate  \n",
       "4                                                                 RT @ChuckNellis: Cruz has class &amp; truth, that gets my vote! #GOPDebate  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¬øQu√© n√∫mero de tweets tenemos en cada dataset? ¬øCu√°ntos de cada clase?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Negative    0.579035\n",
       "Neutral     0.256953\n",
       "Positive    0.164012\n",
       "Name: sentiment, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"sentiment\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¬øQu√© dificultades crees que presenta la diferencia entre la cantidad de clases?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Negative    0.583837\n",
       "Neutral     0.263353\n",
       "Positive    0.152810\n",
       "Name: sentiment, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[\"sentiment\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificador de tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a construir nuestro propio clasificador sobre los tweets que hemos cargado. Los pasos que seguiremos ser√°n:\n",
    "\n",
    "* Preprocesar ambos conjuntos de tweets por separado.\n",
    "* Entrenar clasificador con tweets de entrenamiento.\n",
    "* Evaluar con tweets de test.\n",
    "\n",
    "Primero, haremos una prueba para observar el rendimiento de nuestro clasificador sin ning√∫n tipo de preprocesamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seguimos creando el clasificador y entrenando con el conjunto de entrenamiento de los tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('clf',\n",
       "                 LinearSVC(C=1.0, class_weight=None, dual=True,\n",
       "                           fit_intercept=True, intercept_scaling=1,\n",
       "                           loss='squared_hinge', max_iter=1200,\n",
       "                           multi_class='ovr', penalty='l2', random_state=None,\n",
       "                           tol=0.0001, verbose=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creamos nuestro pipeline con vectorizador (bag of words) y clasificador\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('clf', LinearSVC(max_iter=1200))])\n",
    "\n",
    "# entrenamos el clasificador\n",
    "text_clf.fit(df_train['text'], df_train['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos las predicciones con el conjunto de test y obtenemos la m√©trica de evaluaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5973060845332094"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = text_clf.predict(df_test['text'])\n",
    "np.mean(predicted == df_test['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que hemos obtenido un resultado un poco peor... Ahora es cuando entra en juego el preprocesamiento del texto.\n",
    "\n",
    "Ahora vamos a preprocesar el texto y construir un clasificador. Para ello, se ha creado esta funci√≥n que nos automatiza el preprocesamiento. Deber√°s a√±adir el c√≥digo que creas necesario y ejecutar la funci√≥n para obtener el texto preprocesado. \n",
    "\n",
    "**Puedes definir todas las funciones de preprocesado que creas necesario, pero ten en cuenta varios detalles:**\n",
    "* La funcion `preprocesar_texto` es llamada desde un `apply`. Esto significa que la funci√≥n recibe un tweet y devuelve un tweet preprocesado con cada llamada. \n",
    "* Si el preprocesado es muy agresivo, un tweet puede quedarse f√°cilmente vac√≠o, en esos casos el clasificador no podr√° trabajar con √©l y escupir√° la clase mayoritaria para ese tweet.\n",
    "* Algunas t√©cnicas no tienen sentido si se aplican despu√©s de otras dentro del pipeline. Por ejemplo, no tiene sentido aplicar POS despu√©s de realizar Stemming.\n",
    "* Count Vectorizer necesita DOCUMENTOS y al trabajar con texto muchas veces es m√°s sencillo hacer uso de TOKENS. Esto significa que tendremos que pasar cada tweet preprocesado en una cadena de texto. La funci√≥n `\" \".join(palabras)` que vimos en el worksheet es tu aliada.\n",
    "* Si tu preprocesamiento va a ser intensivo, quiz√°s es buena idea crear varias funciones que sean llamadas desde `preprocesar_texto`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"rt @scottwalker: didn't catch the full #gopdebate last night. here are some of scott's best lines in 90 seconds. #walker16 http://t.co/zsff‚Ä¶\""
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A min√∫sculas\n",
    "def to_lower(text):\n",
    "    return text.lower()\n",
    "\n",
    "text_lower = to_lower(df_train['text'][1])\n",
    "text_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rt', ':', \"didn't\", 'catch', 'the', 'full', '#gopdebate', 'last', 'night', '.', 'here', 'are', 'some', 'of', \"scott's\", 'best', 'lines', 'in', '90', 'seconds', '.', '#walker16', 'http://t.co/zsff‚Ä¶']\n"
     ]
    }
   ],
   "source": [
    "## Tokenizamos\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "def get_tokens(text):\n",
    "    return TweetTokenizer(strip_handles=True).tokenize(text)\n",
    "\n",
    "text_tokens = get_tokens(text_lower)\n",
    "print(text_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rt', 'catch', 'full', '#gopdebate', 'last', 'night', \"scott's\", 'best', 'lines', '90', 'seconds', '#walker16', 'http://t.co/zsff‚Ä¶']\n"
     ]
    }
   ],
   "source": [
    "## Limpiamos stopwords\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "stopwords.extend([\n",
    "    '``','/','=','(',')','\\'','...','-',\n",
    "    ',', '.', ';', ':', '?', '¬ø', '!', '¬°',\n",
    "    '%','üá∏','üá∫','@','http',\n",
    "    '‚Ä¶','\\\"','&','‚Äô','‚Äú','‚Äù','#'\n",
    "])\n",
    "\n",
    "def clean_stopwords(tokens, stopwords):\n",
    "    clean_tokens = []\n",
    "    for token in tokens:\n",
    "        if token in stopwords:\n",
    "            continue\n",
    "        clean_tokens.append(token)\n",
    "    return clean_tokens\n",
    "\n",
    "clean_tokens = clean_stopwords(text_tokens, stopwords)\n",
    "print(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['catch', 'full', 'last', 'night', \"scott's\", 'best', 'lines', '90', 'seconds']\n"
     ]
    }
   ],
   "source": [
    "# limpiamos m√°s basura\n",
    "\n",
    "def clean_twitter_conventions(tokens):\n",
    "    clean_tokens = []\n",
    "    for token in tokens:\n",
    "        if token.find('@') >= 0 or token.find('#') >= 0:\n",
    "            continue\n",
    "            \n",
    "        if token.find('http') >= 0:\n",
    "            continue\n",
    "        \n",
    "        if token == 'rt':\n",
    "            continue\n",
    "        \n",
    "        clean_tokens.append(token)\n",
    "    return clean_tokens\n",
    "\n",
    "clean_tokens = clean_twitter_conventions(clean_tokens)\n",
    "print(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['catch', 'full', 'last', 'night', 'scott', 'best', 'line', '90', 'second']\n"
     ]
    }
   ],
   "source": [
    "# stemming\n",
    "from nltk.stem import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "def get_stemmed_text(clean_tokens, stemmer):\n",
    "    tokens_stem = []\n",
    "    for token in clean_tokens:\n",
    "        tokens_stem.append(stemmer.stem(token))\n",
    "    \n",
    "    return tokens_stem\n",
    "\n",
    "clean_tokens = get_stemmed_text(clean_tokens, stemmer)\n",
    "print(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['catch', 'full', 'last', 'night', 'scott', 'line', 'second']\n"
     ]
    }
   ],
   "source": [
    "# filtrar POS\n",
    "from nltk import pos_tag\n",
    "selected_pos = ['JJ', 'NN', 'NNS']\n",
    "\n",
    "def filter_pos(clean_tokens, selected_tokens, pos_tag):\n",
    "    tokens_filtered = []\n",
    "    pos = pos_tag(clean_tokens)\n",
    "    for p in pos:\n",
    "        if p[1] in selected_pos:\n",
    "            tokens_filtered.append(p[0])\n",
    "            \n",
    "    return tokens_filtered\n",
    "\n",
    "clean_tokens = filter_pos(clean_tokens, selected_tokens, pos_tag)\n",
    "print(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocesar_texto(texto):\n",
    "    \"\"\" Funci√≥n para preprocesamiento de texto.\n",
    "    Args:\n",
    "        texto: cadena de texto a preprocesar.\n",
    "    Returns:\n",
    "        mismo texto preprocesado.\n",
    "    \"\"\"\n",
    "    texto_filtrado = \"\"\n",
    "    texto_filtrado = to_lower(texto)\n",
    "    texto_filtrado = get_tokens(texto_filtrado)\n",
    "    texto_filtrado = clean_stopwords(texto_filtrado, stopwords)\n",
    "    texto_filtrado = clean_twitter_conventions(texto_filtrado)\n",
    "    \n",
    "    # t√©cnicas que con una implementaci√≥n sencilla no logran mejorar resultados\n",
    "    # texto_filtrado = filter_pos(texto_filtrado, selected_tokens, pos_tag)\n",
    "    # texto_filtrado = get_stemmed_text(texto_filtrado, stemmer)\n",
    "    \n",
    "    \n",
    "    texto_filtrado = ' '.join(texto_filtrado)\n",
    "    return texto_filtrado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos el preprocesamiento a los dos conjuntos de tweets y lo guardamos en la columna `prep`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['prep'] = df_train['text'].apply(preprocesar_texto)\n",
    "df_test['prep'] = df_test['text'].apply(preprocesar_texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de reentrenar nuestro clasificador, siempre es recomendable dar un vistazo al resultado del texto. Podemos observar frecuencia de palabras o simplemente generar un WordCloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           everyone feel climate change question last night exactly\n",
       "1                catch full last night scott's best lines 90 seconds\n",
       "2                              mention tamir rice held cleveland wow\n",
       "3        carly fiorina trending hours debate men just-completed says\n",
       "4           w delivered highest ratings history presidential debates\n",
       "5                          liked happy heard going moderator anymore\n",
       "6    deer headlights ben carson may brain surgeon performed lobotomy\n",
       "7                                         last night's debate proved\n",
       "8                                               fairness owns phrase\n",
       "9                                    reading family's comments great\n",
       "Name: prep, dtype: object"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['prep'][0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora s√≠, vamos a reentrenar el clasificador y evaluar de nuevo. Puedes hacer uso del mismo pipeline anterior o simplemente crear uno nuevo con m√°s etapas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nuevo pipeline si es que es necesario. Por defecto usamos el anterior.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "new_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                    ('tfidf', TfidfTransformer(use_idf = True, smooth_idf=True)),\n",
    "                    ('clf', LinearSVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('clf',\n",
       "                 LinearSVC(C=1.0, class_weight=None, dual=True,\n",
       "                           fit_intercept=True, intercept_scaling=1,\n",
       "                           loss='squared_hinge', max_iter=1000,\n",
       "                           multi_class='ovr', penalty='l2', random_state=None,\n",
       "                           tol=0.0001, verbose=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_clf.fit(df_train['text'], df_train['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6228518346493265"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicci√≥n haciendo uso del pipeline correspondiente. ¬°Recuerda cambiarlo si has creado uno nuevo!\n",
    "predicted = new_clf.predict(df_test['prep'])\n",
    "np.mean(predicted == df_test['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ¬øQu√© opinas de los resultados obtenidos?\n",
    "* ¬øPor qu√© crees que ha sucedido esto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¬øPodr√≠as explicarme con tus palabras en qu√© consiste Tf-Idf? ¬øCual es la idea intuitiva de aplicar esta transformaci√≥n a la matriz?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tf-Idf es una t√©cnica que se aplica a la matriz de documentos-t√©rminos. Significa \"term frequency - inverse document frequency\" y es una t√©cnica que especifica c√≥mo de importante es un t√©rmino dentro de una colecci√≥n de documentos. A su vez, est√° formada por dos t√©cnicas diferentes que son las siguientes:\n",
    "\n",
    "* Term frequency: que recompensa aquellas palabras que aparecen a menudo en un documento.\n",
    "* Inverse document frequency: que penaliza aquellas palabras que aparecen a menudo en una colecci√≥n de documentos.\n",
    "\n",
    "Intuitivamente, buscar√° los t√©rminos m√°s importantes para identificar un documento dentro de una colecci√≥n de documentos. Har√° que aumente el valor ponderado del t√©rmino dentro de un documento, pero disminuir√° su valor si este t√©rmino es com√∫n en muchos documentos. A mayor importancia, m√°s alto es el valor en el resultado final."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
